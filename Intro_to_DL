# Introduction to Deep Learning
## Content
* The Perceptron
* Activation Function
* Building Neural Nets with Perceptron
  * Simple Perceptron
  * Multi Output Perceptron
  * Single Layer Neural Network
  * Deep Neural Network
*Apply Neural Networks
*Quantifying Loss
*Empirical Loss
* Binary Cross Entropy Loss
* Mean Squared Error Loss
* Training Neural Networks
* Loss Optimization
* Gradient Descent
  * Computing Gradients
* Loss Function can be difficult to Optimize
* Setting the Learning Rate
  * How to deal with this?
* Adaptive Learning Rate Algorithm
  * Momentum
  * Adagrad
  * Adadelta
  * Adam
  * RMSProp
* Mini Batching
  * Stochastic Gradient Descent
  * Mini Batches while training
* Overfitting
* Regularization
  * Dropout
  * Early Stopping

