# Introduction to Deep Learning
## Content
* The Perceptron
* Activation Function
  Activation Functions are really very importent for ANN to learn and make sence of some thing really complicated and non linear complex     functions mapping between input and output response variables. They introduce non linearity to our neural networksIf we don't apply         activation function then the output signal would simply be a linear function. Activation functions should be differentiable 
  ##Most Populat types of activation functions
    *Sigmoid or Logistic
    *Tanh or Hyperbolic Tangent 
    *Relu Rectified Linear units
   ###Sigmoid Function:
    -Sigmoid Function takes a value as input and outputs another value between 0 and 1
    -Its a non-linear and easy to work with when constructing a neural network model
    -The good part about this function is that it is continuously differentiable over different            values of z and has a fixed output range
    
* Building Neural Nets with Perceptron
  * Simple Perceptron
  * Multi Output Perceptron
  * Single Layer Neural Network
  * Deep Neural Network
*Apply Neural Networks
*Quantifying Loss
*Empirical Loss
* Binary Cross Entropy Loss
* Mean Squared Error Loss
* Training Neural Networks
* Loss Optimization
* Gradient Descent
  * Computing Gradients
* Loss Function can be difficult to Optimize
* Setting the Learning Rate
  * How to deal with this?
* Adaptive Learning Rate Algorithm
  * Momentum
  * Adagrad
  * Adadelta
  * Adam
  * RMSProp
* Mini Batching
  * Stochastic Gradient Descent
  * Mini Batches while training
* Overfitting
* Regularization
  * Dropout
  * Early Stopping
